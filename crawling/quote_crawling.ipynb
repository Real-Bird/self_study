{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "driver = webdriver.Chrome(\"D:/self_study/crawling/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.naver.com\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "elName = driver.find_element_by_name(\"query\")\n",
    "elName.clear()\n",
    "elName.send_keys(\"명언\")\n",
    "elName.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords= [\"사랑\",\"인생\",\"공부\",\"성공\",\"친구\",\"독서\",\"이별\",\"시간\",\"노력\",\"희망\",\"도전\",\"자신감\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = driver.page_source\n",
    "soup = bs(source, 'html.parser')\n",
    "enquote = soup.find_all(\"p\", {\"class\":\"lngeng\"})[0].text\n",
    "enauthor = soup.find_all(\"dt\")[0].find(\"span\", {\"class\": \"engnm\"}).text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enquote: I am extraordinarily patient, provided I get my own way in the end. \n",
      "enauthor: Margaret Thatcher\n"
     ]
    }
   ],
   "source": [
    "print(\"enquote: {0} \\nenauthor: {1}\".format(enquote,enauthor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kr_author = []\n",
    "kr_quote = []\n",
    "en_author = []\n",
    "en_quote = []\n",
    "for i in range(len(keywords)):\n",
    "    time.sleep(1)    \n",
    "    quoteTime = driver.find_element_by_link_text(keywords[i])\n",
    "    quoteTime.click()\n",
    "    source = driver.page_source\n",
    "    soup = bs(source, 'html.parser')\n",
    "    quote = soup.find_all(\"p\", {\"class\":\"lngkr\"})\n",
    "    enquote = soup.find_all(\"p\", {\"class\":\"lngeng\"})\n",
    "    author = soup.find_all(\"dt\")\n",
    "    for j in range(len(quote)):\n",
    "        authorX = author[j].find(\"a\").get_text()\n",
    "        authorY = author[j].find(\"span\", {\"class\": \"engnm\"}).text\n",
    "        quoteX = quote[j].text\n",
    "        quoteY = enquote[j].text\n",
    "        kr_author.append(authorX)\n",
    "        kr_quote.append(quoteX)\n",
    "        en_author.append(authorY)\n",
    "        en_quote.append(quoteY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame({\"k-name\":kr_author,\"k-quote\":kr_quote})\n",
    "y = pd.DataFrame({\"e-name\":en_author,\"e-quote\":en_quote})\n",
    "quotes_df = pd.concat([x, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_df.to_csv(\"quotes.csv\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "435c7524b81c754d2a38f9b1930a50d7a83318eec9a7b6faab8c4b8cfd59b603"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
